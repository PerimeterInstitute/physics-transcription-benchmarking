Okay, so why we often need Markov Chain Monte Carlo is that in real life these models and
likelihoods are often pretty complicated.
So the constraints are kind of complicated and we can't really represent them in analytic
form.
But you can represent them by drawing samples from the distribution and MCMC is a way of
drawing samples from a probability distribution when you can compute it numerically but you
can't represent it analytically or can't solve it analytically.
Okay right and I have just a couple, just little like sketches of results from the literature
where they've used to sampling to represent a kind of complicated or weird parameter space.
and in the lab you'll produce these little like corner plots like this.
So a nice aspect of being able to draw samples from a distribution like this is that you
can, if you only care about one of them like say one of them is a nuisance parameter you
can project them off onto one of the axes and then read off that value, read off that
distribution and it's a like correct representation of your uncertainty in that parameter alone
as well.
They often come up in cosmology.
It's all like contour plots of like what things what parameters are allowed by certain data
sets.
Usually as the field has like gone from very broad measurements to getting more precise
they've become more kind of elliptical and Gaussian so it's kind of gotten boring.
Boring used to be like large bananas in the chat you were always like going for smaller
and smaller bananas but now it's kind of turned into oranges or something it's not quite as
exciting but you know this is a pretty weird looking probability space talking about whether,
whether the initial conditions of the universe are Gaussian or not basically something like that
Okay, so back to Dan's flashy slides.
Basically you know as I said before MCMC lets you draw samples from a probability distribution
and all you have to do is, all you have to be able to do is evaluate the function.
Excuse me, so the generative modeling part is like all about laying out what that function
is and then MCMC allows you to draw samples from it which then lets you make inferences
and draw results from it.
Okay so, right so, this is going to, the next handful of slides take you through just an
illustration of how the algorithm works or what it looks like in action.
and what we're looking at is there are no axes so the axes aren't labeled that's not
Dan's style.
But we're imagining that we're in some parameter space say that parameter space of like Omega
M Omega Lambda right and we've taken some data like some data set that constrains those parameters
and the contours are the probability contours.
So the center of that contour would be an area in that parameter space that is consistent
with the data and then as you move away down on those contours, those parameters become
more and more inconsistent with the data.
Does that make sense?
I know it's like kind of a very abstract kind of illustration.
Okay so, say and I should say this they're kind of different flavors of Markov Chain Monte
Carlo MCMC and one of them by far the most common is Metropolis Hastings.
So it's just the kind of the details of the algorithm.
But so in this algorithm you start, you choose some starting point in this parameter space
and then basically propose, you're going to basically move around a point or a sample
or a walker, those are all sort of equivalent terms, by proposing to jump from where you
are in the parameter space to some different place in the parameter space.
Usually that proposal is some sort of like something like a Gaussian like you say oh, 
I'm just going to draw a Gaussian sample that moves me from where I am to some other
place in the parameter space.
And then you, this is too much math, but I can't really I don't have the source file
so I can't modify Dan's slides.
So once you've proposed moving to a new place you compute whether the probability there
is better or worse than where you were.
And if it's better you always take it and if it's worse you sometimes take it.
And you and that sometimes is in proportion to how much worse it is.
So if you're, if it's 25 percent as good you take the jump 25 percent of the time.
so as Dan highlights it only involves these relative probabilities.
For most of the time these cues which are that proposal distribution, usually they're
symmetric, so the jumping one way or the other are the same so they cancel out.
and actually in the lab I didn't even include that term because I was assuming Gaussian
proposal distributions.
Okay.
Yeah.
So, and then you just iterate this process over and over, so propose jumping to a new
place accept to the jump if it improves your probability, reject it if it doesn't or sorry,
if it makes the probability worse than probabilistically accept or reject it.
And then that, you know, carries on and on.
So one little like seems like a weird technicality or like a weird thing to do is that when you
reject a move, you still store another copy of where you decided to stay in the results.
And then you know in theory, it makes its way from wherever you initialized it to the
bulk of the probability distribution and then spends all its time happily wandering around
that space drawing samples from that distribution.
and then at the end of the day what you have is this bunch of samples and what MCMC
promises is that in the limit of infinite time, those samples are drawn fairly from that
probability distribution.
Now in the limit of infinite time is a pretty big catch.
It's why like a lot of people actually like actively work on MCMC instead of it just being 
like a solved thing.
Okay so any questions about kind of the intuition part of the algorithm.
Maybe why is it important to store that second copy if in theory it seems that you have a very
large number of points anyway.
Why would that make an element different.
Yeah, it's a good question.
I guess it I mean I guess a kind of intuitive way of thinking about it is that it was a
good enough place that you decided to stay there even if you, even though you were given
another choice of somewhere else to go.
so it's been kind of fair to keep another copy of it.
The way it comes out of the math is that, in order for MC to actually do that thing
it promises to draw fairly from the distribution, you need to satisfy this condition called
detailed balance.
there's connections to thermodynamics or like thermal physics there.
And basically it's like the,
Once it's hit this like,
I'm losing my words.
Once it's hit this stable distribution, you need the probability of being at
at one point and jumping to another point for that to be reversible.
So and then basically storing that extra copy ensures that that holds.
That's not a very satisfying answer in some ways.
