{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Test import Test\n",
    "from models.WhisperPI import WhisperPI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperPI(\"whisper_pi_large\",\n",
    "                  {\n",
    "                    \"model_type\": \"large\",\n",
    "                    \"language\": \"en\"\n",
    "                  }\n",
    ")\n",
    "\n",
    "model_med = WhisperPI(\"whisper_pi_medium\",\n",
    "                  {\n",
    "                    \"model_type\": \"medium\",\n",
    "                    \"language\": \"en\"\n",
    "                  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/unity/unixhome/rmohl/.local/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/nfs/unity/unixhome/rmohl/.local/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/nfs/unity/unixhome/rmohl/.local/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/nfs/unity/unixhome/rmohl/.local/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/nfs/unity/unixhome/rmohl/.local/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/nfs/unity/unixhome/rmohl/.local/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "test = Test([model, model_med], dataset_path=\"dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'whisper_pi_medium': {'dustin_lang': {'load_time': '0:05:43.108026', 'transcribe_time': '0:00:54.956891', 'test_results': {'word_error_rate': 0.2191780821917808, 'match_error_rate': 0.1951219512195122, 'word_information_lost': 0.272302038088874, 'word_information_preserved': 0.727697961911126, 'character_error_rate': 0.05084745762711865}}, 'erik_schnetter': {'load_time': '0:05:43.108026', 'transcribe_time': '0:00:49.013099', 'test_results': {'word_error_rate': 0.19047619047619047, 'match_error_rate': 0.17647058823529413, 'word_information_lost': 0.2679738562091504, 'word_information_preserved': 0.7320261437908496, 'character_error_rate': 0.019178082191780823}}, 'lucien_hardy': {'load_time': '0:05:43.108026', 'transcribe_time': '0:02:34.648378', 'test_results': {'word_error_rate': 0.319047619047619, 'match_error_rate': 0.29646017699115046, 'word_information_lost': 0.45279220779220775, 'word_information_preserved': 0.5472077922077923, 'character_error_rate': 0.13122171945701358}}}, 'whisper_pi_large': {'dustin_lang': {'load_time': '0:00:32.582526', 'transcribe_time': '0:01:35.986448', 'test_results': {'word_error_rate': 0.2191780821917808, 'match_error_rate': 0.1951219512195122, 'word_information_lost': 0.272302038088874, 'word_information_preserved': 0.727697961911126, 'character_error_rate': 0.05084745762711865}}, 'erik_schnetter': {'load_time': '0:00:32.582526', 'transcribe_time': '0:01:27.272061', 'test_results': {'word_error_rate': 0.12698412698412698, 'match_error_rate': 0.11940298507462686, 'word_information_lost': 0.17531390665719027, 'word_information_preserved': 0.8246860933428097, 'character_error_rate': 0.010958904109589041}}, 'lucien_hardy': {'load_time': '0:00:32.582526', 'transcribe_time': '0:04:12.492743', 'test_results': {'word_error_rate': 0.21428571428571427, 'match_error_rate': 0.20361990950226244, 'word_information_lost': 0.3202545534342769, 'word_information_preserved': 0.6797454465657231, 'character_error_rate': 0.06334841628959276}}}}\n"
     ]
    }
   ],
   "source": [
    "print(test.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj = json.dumps(test.results, indent=4)\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    f.write(json_obj)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dustin_lang_2-30sec.mp4': \" Okay, so why we often need Markov Chain Monte Carlo is that in real life these models and likelihoods are often pretty complicated. So the constraints are kind of complicated and we can't really represent them in analytic form. But you can represent them by drawing samples from the distribution. And MCMC is a way of drawing samples from a probability distribution when you can compute You can compute it numerically but you can't represent it analytically or can't solve it analytically.\", 'erik_schnetter_1-30sec.mp4': \" It does. Okay. So, every object in Julia has a particular type. For example, the type of A is a double position matrix. It's not just the matrix, it's a double position matrix. If you look to probably the second lecture, I spoke about types and generic programming. Let's just actually look at the result here. The compiler knows that A is a type matrix of float 64.\", 'lucien_hardy_1-2min.mp4': \" Okay, any pure state can be written like that in some basis. And this provides you with, these are complex numbers, you have two n complex numbers. Okay. Then you need to subtract one because of the overall phase, another one because we want to impose normalization. Okay. So, a lot of our intuition comes from the special case n equal to two, you know, a qubit. And there's something bad about this special case, we're trying to get an intuition for the shape of state space. Let's see, so if n equals two, k minus two, which is the, well, let me just do all of it. So the, that means k equals four, k minus one, which is the, I can just do this here actually. Yeah, so this one, k minus one equals three, you can check my arithmetic. K minus two equals two. So this is all consistent because we know that we have the block ball and the boundary of the block ball has two dimensions in it. And then also, if you look at this here, you get a pure dimension that's two n minus two is also two. Okay. So in the case of the qubit, these two things are the same. Okay. Well, that isn't true usually. Let's take n equals three.\"}\n",
      "{'dustin_lang_2-30sec.mp4': '0:00:54.956891', 'erik_schnetter_1-30sec.mp4': '0:00:49.013099', 'lucien_hardy_1-2min.mp4': '0:02:34.648378'}\n"
     ]
    }
   ],
   "source": [
    "print(model_med.transcription)\n",
    "print(model_med.transcribe_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
